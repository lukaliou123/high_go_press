package main

import (
	"context"
	"fmt"
	"net"
	"os"
	"os/signal"
	"syscall"
	"time"

	"high-go-press/api/proto/common"
	"high-go-press/api/proto/counter"
	"high-go-press/internal/dao"
	"high-go-press/pkg/kafka"

	"github.com/go-redis/redis/v8"
	"go.uber.org/zap"
	"google.golang.org/grpc"
	"google.golang.org/grpc/codes"
	"google.golang.org/grpc/reflection"
)

// CounterServer å¸¦Rediså’ŒKafkaé›†æˆçš„CounteræœåŠ¡å®ç°
type CounterServer struct {
	counter.UnimplementedCounterServiceServer
	logger       *zap.Logger
	redisDAO     *dao.RedisRepo
	kafkaManager *kafka.KafkaManager
	eventCounter int64 // äº‹ä»¶è®¡æ•°å™¨
}

func NewCounterServer(logger *zap.Logger, redisDAO *dao.RedisRepo, kafkaManager *kafka.KafkaManager) *CounterServer {
	return &CounterServer{
		logger:       logger,
		redisDAO:     redisDAO,
		kafkaManager: kafkaManager,
		eventCounter: 0,
	}
}

func (s *CounterServer) IncrementCounter(ctx context.Context, req *counter.IncrementRequest) (*counter.IncrementResponse, error) {
	if req.ResourceId == "" || req.CounterType == "" {
		return &counter.IncrementResponse{
			Status: &common.Status{
				Success: false,
				Message: "resource_id and counter_type are required",
				Code:    int32(codes.InvalidArgument),
			},
		}, nil
	}

	delta := req.Delta
	if delta == 0 {
		delta = 1
	}

	// ğŸ”§ ä¿®å¤: ä½¿ç”¨ç»Ÿä¸€çš„Redis keyæ ¼å¼
	key := fmt.Sprintf("counter:%s:%s", req.ResourceId, req.CounterType)

	// ğŸ”§ ä¿®å¤: ä½¿ç”¨Redisè€Œä¸æ˜¯å†…å­˜å­˜å‚¨
	newValue, err := s.redisDAO.IncrementCounter(ctx, key, delta)
	if err != nil {
		s.logger.Error("Failed to increment counter in Redis",
			zap.String("key", key),
			zap.Int64("delta", delta),
			zap.Error(err))

		return &counter.IncrementResponse{
			Status: &common.Status{
				Success: false,
				Message: "Failed to increment counter",
				Code:    int32(codes.Internal),
			},
		}, nil
	}

	s.logger.Info("Counter incremented",
		zap.String("key", key),
		zap.Int64("delta", delta),
		zap.Int64("new_value", newValue))

	// ğŸ”¥ å‘é€Kafkaäº‹ä»¶
	if err := s.sendCounterEvent(ctx, req.ResourceId, req.CounterType, delta, newValue); err != nil {
		s.logger.Error("Failed to send counter event", zap.Error(err))
		// æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¸è¿”å›é”™è¯¯ï¼Œå› ä¸ºè®¡æ•°å™¨æ›´æ–°å·²ç»æˆåŠŸ
		// åªæ˜¯äº‹ä»¶å‘é€å¤±è´¥ï¼Œå¯ä»¥è€ƒè™‘é‡è¯•æˆ–å¼‚æ­¥å¤„ç†
	}

	return &counter.IncrementResponse{
		Status: &common.Status{
			Success: true,
			Message: "Counter incremented successfully",
			Code:    int32(codes.OK),
		},
		CurrentValue: newValue,
		ResourceId:   req.ResourceId,
		CounterType:  req.CounterType,
	}, nil
}

// sendCounterEvent å‘é€è®¡æ•°å™¨äº‹ä»¶åˆ°Kafka
func (s *CounterServer) sendCounterEvent(ctx context.Context, resourceID, counterType string, delta, newValue int64) error {
	s.eventCounter++

	event := &kafka.CounterEvent{
		EventID:     fmt.Sprintf("evt_%d_%d", time.Now().Unix(), s.eventCounter),
		ResourceID:  resourceID,
		CounterType: counterType,
		Delta:       delta,
		NewValue:    newValue,
		Timestamp:   time.Now(),
		Source:      "counter-microservice",
	}

	producer := s.kafkaManager.GetProducer()
	return producer.SendCounterEvent(ctx, event)
}

func (s *CounterServer) GetCounter(ctx context.Context, req *counter.GetCounterRequest) (*counter.GetCounterResponse, error) {
	if req.ResourceId == "" || req.CounterType == "" {
		return &counter.GetCounterResponse{
			Status: &common.Status{
				Success: false,
				Message: "resource_id and counter_type are required",
				Code:    int32(codes.InvalidArgument),
			},
		}, nil
	}

	// ğŸ”§ ä¿®å¤: ä½¿ç”¨ç»Ÿä¸€çš„Redis keyæ ¼å¼
	key := fmt.Sprintf("counter:%s:%s", req.ResourceId, req.CounterType)

	// ğŸ”§ ä¿®å¤: ä»Redisè·å–è€Œä¸æ˜¯å†…å­˜
	value, err := s.redisDAO.GetCounter(ctx, key)
	if err != nil {
		s.logger.Error("Failed to get counter from Redis",
			zap.String("key", key),
			zap.Error(err))

		return &counter.GetCounterResponse{
			Status: &common.Status{
				Success: false,
				Message: "Failed to get counter",
				Code:    int32(codes.Internal),
			},
		}, nil
	}

	return &counter.GetCounterResponse{
		Status: &common.Status{
			Success: true,
			Message: "Counter retrieved successfully",
			Code:    int32(codes.OK),
		},
		Value:       value,
		ResourceId:  req.ResourceId,
		CounterType: req.CounterType,
		LastUpdated: &common.Timestamp{
			Seconds: time.Now().Unix(),
			Nanos:   int32(time.Now().Nanosecond()),
		},
	}, nil
}

func (s *CounterServer) BatchGetCounters(ctx context.Context, req *counter.BatchGetRequest) (*counter.BatchGetResponse, error) {
	results := make([]*counter.GetCounterResponse, 0, len(req.Requests))

	// ğŸ”§ ä¿®å¤: ä½¿ç”¨Redisæ‰¹é‡è·å–
	keys := make([]string, 0, len(req.Requests))
	keyToReq := make(map[string]*counter.GetCounterRequest)

	for _, r := range req.Requests {
		if r.ResourceId == "" || r.CounterType == "" {
			continue
		}

		key := fmt.Sprintf("counter:%s:%s", r.ResourceId, r.CounterType)
		keys = append(keys, key)
		keyToReq[key] = r
	}

	if len(keys) == 0 {
		return &counter.BatchGetResponse{
			Status: &common.Status{
				Success: true,
				Message: "Empty batch request",
				Code:    int32(codes.OK),
			},
			Counters: results,
		}, nil
	}

	// æ‰¹é‡ä»Redisè·å–
	values, err := s.redisDAO.GetMultiCounters(ctx, keys)
	if err != nil {
		s.logger.Error("Failed to batch get counters from Redis", zap.Error(err))
		return &counter.BatchGetResponse{
			Status: &common.Status{
				Success: false,
				Message: "Failed to batch get counters",
				Code:    int32(codes.Internal),
			},
		}, nil
	}

	for _, key := range keys {
		r := keyToReq[key]
		if r == nil {
			continue
		}

		value := values[key] // Redisä¼šè¿”å›0å¦‚æœkeyä¸å­˜åœ¨

		results = append(results, &counter.GetCounterResponse{
			Status: &common.Status{
				Success: true,
				Message: "Success",
				Code:    int32(codes.OK),
			},
			Value:       value,
			ResourceId:  r.ResourceId,
			CounterType: r.CounterType,
			LastUpdated: &common.Timestamp{
				Seconds: time.Now().Unix(),
				Nanos:   int32(time.Now().Nanosecond()),
			},
		})
	}

	return &counter.BatchGetResponse{
		Status: &common.Status{
			Success: true,
			Message: "Batch get completed",
			Code:    int32(codes.OK),
		},
		Counters: results,
	}, nil
}

func (s *CounterServer) HealthCheck(ctx context.Context, req *counter.HealthCheckRequest) (*counter.HealthCheckResponse, error) {
	// æ£€æŸ¥Redisè¿æ¥
	_, err := s.redisDAO.GetCounter(ctx, "health_check_test")
	if err != nil {
		return &counter.HealthCheckResponse{
			Status: &common.Status{
				Success: false,
				Message: "Redis connection failed",
				Code:    int32(codes.Unavailable),
			},
			Service: "counter",
			Details: map[string]string{
				"redis": "unhealthy",
				"error": err.Error(),
			},
		}, nil
	}

	// è·å–Kafkaå¥åº·çŠ¶æ€
	kafkaHealth := s.kafkaManager.HealthCheck()

	details := map[string]string{
		"redis":       "healthy",
		"event_count": fmt.Sprintf("%d", s.eventCounter),
		"kafka_mode":  fmt.Sprintf("%v", kafkaHealth["mode"]),
	}

	return &counter.HealthCheckResponse{
		Status: &common.Status{
			Success: true,
			Message: "Service is healthy",
			Code:    int32(codes.OK),
		},
		Service: "counter",
		Details: details,
	}, nil
}

func main() {
	// åˆ›å»ºlogger
	logger, _ := zap.NewDevelopment()
	defer logger.Sync()

	logger.Info("Starting Counter microservice with Redis and Kafka integration...",
		zap.String("service", "counter"),
		zap.String("version", "2.0.0"))

	// ğŸ”§ åˆå§‹åŒ–Redisè¿æ¥
	redisClient := redis.NewClient(&redis.Options{
		Addr:     "localhost:6379", // å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®
		Password: "",               // å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®
		DB:       0,                // å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®
	})

	// æµ‹è¯•Redisè¿æ¥
	ctx := context.Background()
	_, err := redisClient.Ping(ctx).Result()
	if err != nil {
		logger.Fatal("Failed to connect to Redis", zap.Error(err))
	}

	logger.Info("âœ… Redis connection established successfully")

	// åˆ›å»ºRedis DAO
	redisDAO := &dao.RedisRepo{}
	redisDAO.SetClient(redisClient)
	redisDAO.SetLogger(logger)

	// ğŸ”¥ åˆå§‹åŒ–Kafkaï¼ˆä½¿ç”¨Mockæ¨¡å¼å¼€å§‹ï¼‰
	kafkaConfig := kafka.DefaultKafkaConfig()
	kafkaConfig.Mode = kafka.ModeMock // å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶æ”¹å˜

	// å¦‚æœè®¾ç½®äº†ç¯å¢ƒå˜é‡ï¼Œåˆ‡æ¢åˆ°çœŸå®Kafka
	if os.Getenv("KAFKA_MODE") == "real" {
		kafkaConfig.Mode = kafka.ModeReal
		kafkaConfig.Producer.Brokers = []string{os.Getenv("KAFKA_BROKERS")}
		if len(kafkaConfig.Producer.Brokers) == 0 || kafkaConfig.Producer.Brokers[0] == "" {
			kafkaConfig.Producer.Brokers = []string{"localhost:9092"}
		}
		logger.Info("Using real Kafka",
			zap.Strings("brokers", kafkaConfig.Producer.Brokers))
	}

	kafkaManager, err := kafka.NewKafkaManager(kafkaConfig, logger)
	if err != nil {
		logger.Fatal("Failed to initialize Kafka manager", zap.Error(err))
	}
	defer kafkaManager.Close()

	logger.Info("âœ… Kafka manager initialized successfully",
		zap.String("mode", string(kafkaManager.GetMode())))

	// åˆ›å»ºgRPCæœåŠ¡å™¨
	grpcServer := grpc.NewServer()

	// æ³¨å†ŒCounteræœåŠ¡
	counterSrv := NewCounterServer(logger, redisDAO, kafkaManager)
	counter.RegisterCounterServiceServer(grpcServer, counterSrv)

	// å¯ç”¨åå°„ (ç”¨äºgrpcurlç­‰å·¥å…·)
	reflection.Register(grpcServer)

	// ç›‘å¬ç«¯å£
	listen, err := net.Listen("tcp", ":9001")
	if err != nil {
		logger.Fatal("Failed to listen", zap.Error(err))
	}

	// å¯åŠ¨æœåŠ¡å™¨
	go func() {
		logger.Info("Counter gRPC server starting",
			zap.String("address", listen.Addr().String()))

		if err := grpcServer.Serve(listen); err != nil {
			logger.Error("gRPC server failed", zap.Error(err))
		}
	}()

	// ç­‰å¾…ä¸­æ–­ä¿¡å·
	quit := make(chan os.Signal, 1)
	signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)
	<-quit

	logger.Info("Shutting down Counter service...")

	// ä¼˜é›…å…³é—­
	redisClient.Close()
	grpcServer.GracefulStop()

	logger.Info("Counter service stopped gracefully")
}
